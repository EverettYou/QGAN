{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantum Generative Adversarial Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains documentation of the algorithm and testing codes. First run the following line to load the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run 'QGAN.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class `Pauli`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pauli(Xs, Zs, L)` representes a Pauli (string) operator labeled by\n",
    "- two sets $\\mathcal{X}$ (`Xs`) and $\\mathcal{Z}$ (`Zs`)  that specifies the positions on which $\\sigma^x$ and $\\sigma^z$ act respectively,\n",
    "- and a integer `L` that specifies the total number of qubits on which the Pauli operator acts.\n",
    "\n",
    "$$\\sigma = \\mathrm{i}^{|\\mathcal{X}\\cap\\mathcal{Z}|}\\otimes_{i\\in\\mathcal{X}} \\sigma_i^1\\otimes_{i\\in\\mathcal{Z}}\\sigma_i^3$$\n",
    "\n",
    "`Pauli.mat()` returns the matrix representation (in terms of scipy CSR sparse array) of the Pauli operator. We assume all local operators are modeled by Pauli operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.+0.j,  0.-1.j,  0.+0.j,  0.+0.j],\n",
       "        [ 0.+1.j,  0.+0.j,  0.+0.j,  0.+0.j],\n",
       "        [ 0.+0.j,  0.+0.j,  0.+0.j,  0.+1.j],\n",
       "        [ 0.+0.j,  0.+0.j,  0.-1.j,  0.+0.j]]), σ[3, 2])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = Pauli({1},{0,1}, 2) \n",
    "op.mat().toarray(), op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class `Model`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model(L, loc = 2)` model a system of length `L` (number of qubits) on with local operators supported on `loc` adjacent sites. Periodic boundary condition is assumed.\n",
    "- `Model.ops` holds the basis of local operators.\n",
    "- `Model.opdim` is the dimension of the local operator space.\n",
    "- `Model.M(h)` returns the correlation matrix on the ground state on the Hamiltonian $H$ given by its vector representation `h` in the local operator space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple one qubit model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, [σ[1], σ[2], σ[3]])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = Model(1)\n",
    "# Hilbert space dim, operator space dim, operators\n",
    "mdl.dim, mdl.opdim, mdl.ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the ground state of correlation matrix recovers the Hamiltonian nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.41659745,  0.54776062,  0.72553764]),\n",
       " array([ 0.41659745,  0.54776062,  0.72553764]))"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = randvec(mdl.opdim)\n",
    "M = mdl.M(h)\n",
    "h, GS(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More serious 10-qubit model. Calculate the fidelity between the Hamiltonian and the ground state of the correlation matrix. The fidelity is typically ~ 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = Model(10)\n",
    "h = randvec(mdl.opdim)\n",
    "M = mdl.M(h)\n",
    "abs(GS(M).dot(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is built, the calculation of correlation matrix can be faster (~ 100ms to generate a sample of (H,M) pair for 10-qubit system). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 112 ms, sys: 3.71 ms, total: 116 ms\n",
      "Wall time: 120 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "h = randvec(mdl.opdim)\n",
    "M = mdl.M(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class `MPS`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MPS(lenth, dim, max_dim = 8, lr = 0.001)` creates an MPS of length `length` with the output dimension `dim` (which should match the operator space dimension). The internal auxilary bond dimension is not fixed but has a upper limit set by `max_dim`. The learning rate is set by `lr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mps = MPS(5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic functions:\n",
    "- `MPS.initialize(val)` initializes the MPS to be a two-way multiplier between the left and the right auxilary spaces, with the multiplication factor set by `val`, given the physical legs are pinned to $(1,0,0\\cdots)$.\n",
    "- `MPS.pin(phys_env)` pins all physical legs to the physical environment vector `phys_env`.\n",
    "- `MPS.fromright(right_env)` takes the right environment vecotor `right_env` from the right end and push it all the way to the left, returning the output on the left end (typically used to pass the random source forward).\n",
    "- `MPS.fromleft(left_env)` takes the left environment vector `left_env` from the left end and push it all the way to the right, returning the output on the right end (typically used to propagate the gradient backward)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  6.])"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.initialize(2.)\n",
    "mps.pin([1,0,0])\n",
    "mps.fromleft([1,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our application, we will always take the right auxilary space as the latent space and the left auxilary space as the operator space. Given the physical legs pinned,\n",
    "- `MPS.evaluate()` contract the right auxilary space and returns the density matrix in the operator space,\n",
    "- `MPS.update(grad)` pass down the gradient of the density matrix `grad`, the MPS will be updated by ascending the gradient using the stocastic training method. (One should not expect the density matrix to be updated by the exact among of gradient, because the gradient signal is just a force acting on the MPS, how the MPS response to the force with displacement still depends on the stiffness, but different matrix element has different stiffness so the update outcome is onlu roughly along the gradient ascending direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.,  0.],\n",
       "       [ 0.,  4.]])"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.67782278,  1.4174439 ],\n",
       "       [ 1.4174439 ,  4.85481607]])"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mps.update(0.01*numpy.array([[0,1],[1,0]]))\n",
    "mps.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interface functions (with pytorch) for MPS optimization.\n",
    "- `MPS.getP(h)` given the Hamiltonian (in vector form) `h`, calculate the density matrix by pinning the physical legs to $v=(1,h)$. The latent space is integrated over, s.t.\n",
    "$$P(h)=MPS(h)\\cdot MPS(h)^\\intercal.$$\n",
    "- `MPS.optimize(V)` gradient **descent** the value function `V` by updating the MPS. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a objective $P_0$ to approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "P0 = torch.autograd.Variable(torch.Tensor(numpy.array(\n",
    "            [[0.7,0.1],\n",
    "             [0.1,0.3]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MPS can be simply trained by considering the quadratic loss function. Using the stocastic training approach by sampling random vectors in the latent space, the convergence looks great. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.]\n",
      " [ 0.  1.]] [ 0.59999996]\n",
      "[[ 0.77360308  0.15239084]\n",
      " [ 0.15239084  0.3149952 ]] [ 0.01113187]\n",
      "[[ 0.70194817  0.09709518]\n",
      " [ 0.09709518  0.30814871]] [  8.70726362e-05]\n",
      "[[ 0.7008909   0.10005269]\n",
      " [ 0.10005269  0.30040869]] [  9.66293101e-07]\n"
     ]
    }
   ],
   "source": [
    "mps.initialize(1.)\n",
    "for i in range(200):\n",
    "    P = mps.getP([0.2,0.4])\n",
    "    V = torch.sum((P - P0)**2)\n",
    "    mps.optimize(V)\n",
    "    if i%50 == 0:\n",
    "        print(P.data.numpy(), V.data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Class `GM`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GM(L, depth, loss_fn = \"MSE\")` build a generative model of system size `L` and MPS depth `depth`. Trained using the loss function specified by `loss_fn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1622,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run \"QGAN.py\"\n",
    "gm = GM(1, 3, loss_fn = 'JSD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1623,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'h fidelity': 0.40904110837347185, 'M deviation': 0.17470390650906359}\n",
      "{'h fidelity': 0.72370532049053793, 'M deviation': 0.086724218403669756}\n",
      "{'h fidelity': 0.99562372370029106, 'M deviation': 0.020045222316304935}\n",
      "{'h fidelity': 0.99724377729966729, 'M deviation': 0.0046568962042187979}\n",
      "{'h fidelity': 0.99948108656422363, 'M deviation': 0.00094357419558209845}\n",
      "{'h fidelity': 0.99969577740283455, 'M deviation': 0.00046437606099845565}\n",
      "{'h fidelity': 0.99972710587171354, 'M deviation': 0.00033280008692989423}\n",
      "{'h fidelity': 0.9998646142497809, 'M deviation': 0.00018074854474282704}\n",
      "{'h fidelity': 0.99991146399777397, 'M deviation': 0.00013603845579194035}\n",
      "{'h fidelity': 0.99992941874697427, 'M deviation': 0.00011384342417081287}\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    loss = gm.train()\n",
    "    if i%50 == 0:\n",
    "        print(gm.test())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Profiling the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file '/var/folders/tl/lwpcq5qj049ftcj7pvhkzv_h0000gn/T/tmpar0u4dyp'. \n"
     ]
    }
   ],
   "source": [
    "%reload_ext snakeviz\n",
    "%snakeviz gm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
